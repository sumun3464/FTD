{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"team assignment.ipynb","provenance":[],"mount_file_id":"1MmuPwXDNcM03Ak7uLwXmZ0633kozVSv_","authorship_tag":"ABX9TyMmC3gk4hSScvQBj21VePjt"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rvZwH3NIQ6Dn","executionInfo":{"status":"ok","timestamp":1654824234164,"user_tz":-540,"elapsed":119355,"user":{"displayName":"문서연","userId":"00100794801960082303"}},"outputId":"131b2ec0-3a67-47ca-8981-ca7deef5fb9f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (6.1.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.64.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n","Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2022.5.18.1)\n","Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.7/dist-packages (0.8.1)\n","Collecting imbalanced-learn\n","  Downloading imbalanced_learn-0.9.1-py3-none-any.whl (199 kB)\n","\u001b[K     |████████████████████████████████| 199 kB 3.8 MB/s \n","\u001b[?25h  Downloading imbalanced_learn-0.9.0-py3-none-any.whl (199 kB)\n","\u001b[K     |████████████████████████████████| 199 kB 8.9 MB/s \n","\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.1.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (3.1.0)\n","Requirement already satisfied: scikit-learn>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.0.2)\n","Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.21.6)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.4.1)\n","Installing collected packages: imbalanced-learn\n","  Attempting uninstall: imbalanced-learn\n","    Found existing installation: imbalanced-learn 0.8.1\n","    Uninstalling imbalanced-learn-0.8.1:\n","      Successfully uninstalled imbalanced-learn-0.8.1\n","Successfully installed imbalanced-learn-0.9.0\n","cp: cannot stat 'kaggle.json': No such file or directory\n","chmod: cannot access '/root/.kaggle/kaggle.json': No such file or directory\n","Traceback (most recent call last):\n","  File \"/usr/local/bin/kaggle\", line 5, in <module>\n","    from kaggle.cli import main\n","  File \"/usr/local/lib/python3.7/dist-packages/kaggle/__init__.py\", line 23, in <module>\n","    api.authenticate()\n","  File \"/usr/local/lib/python3.7/dist-packages/kaggle/api/kaggle_api_extended.py\", line 166, in authenticate\n","    self.config_file, self.config_dir))\n","OSError: Could not find kaggle.json. Make sure it's located in /root/.kaggle. Or use the environment method.\n","unzip:  cannot find or open fraudulent-transactions-data.zip, fraudulent-transactions-data.zip.zip or fraudulent-transactions-data.zip.ZIP.\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 6362620 entries, 0 to 6362619\n","Data columns (total 11 columns):\n"," #   Column          Dtype  \n","---  ------          -----  \n"," 0   step            int64  \n"," 1   type            object \n"," 2   amount          float64\n"," 3   nameOrig        object \n"," 4   oldbalanceOrg   float64\n"," 5   newbalanceOrig  float64\n"," 6   nameDest        object \n"," 7   oldbalanceDest  float64\n"," 8   newbalanceDest  float64\n"," 9   isFraud         int64  \n"," 10  isFlaggedFraud  int64  \n","dtypes: float64(5), int64(3), object(3)\n","memory usage: 534.0+ MB\n"]}],"source":["# -*- coding: utf-8 -*-\n","\n","\n","# 전처리 & 정규화\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","!pip install kaggle --upgrade\n","!pip install -U imbalanced-learn\n","\n","!mkdir -p ~/.kaggle\n","!cp kaggle.json ~/.kaggle\n","!chmod 600 ~/.kaggle/kaggle.json\n","\n","!kaggle datasets download -d chitwanmanchanda/fraudulent-transactions-data\n","\n","!unzip fraudulent-transactions-data.zip\n","\n","import numpy as np\n","import pandas as pd\n","import os\n","import warnings\n","warnings.filterwarnings('ignore')\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","\n","df=pd.read_csv('/content/drive/MyDrive/ml/data/Fraud.csv')\n","\n","df.head()\n","\n","df.info()\n","\n","df.isnull().sum()\n","\n","df['type'].nunique()\n","\n","df['nameOrig'].nunique()\n","\n","df['nameDest'].nunique()\n","\n","df['isFraud'].value_counts()\n","\n","df.describe()\n","\n","df.groupby(['isFraud', 'type']).size().unstack(fill_value=0)\n","\n","# one-hot encoder\n","types = pd.get_dummies(df['type'])\n","types.head()\n","\n","# label encoder\n","from sklearn.preprocessing import LabelEncoder\n","label = LabelEncoder()\n","df['nameOrig'] = label.fit_transform(df['nameOrig'])\n","df['nameDest'] = label.fit_transform(df['nameDest'])\n","\n","df = pd.concat([df, types], axis=1)\n","df = df.drop('type', axis=1)\n","df.head()\n","\n","X = df.drop('isFraud', axis = 1) # feature\n","y = df['isFraud'] # label\n","\n","X.shape, y.shape\n","\n","from imblearn.under_sampling import RandomUnderSampler\n","\n","rus = RandomUnderSampler(random_state=0)\n","X_under, y_under = rus.fit_resample(X, y)\n","\n","X_train_under, X_test_under, y_train_under, y_test_under = train_test_split(X_under, y_under, test_size=0.2, random_state=0)\n","X_train_under.shape, X_test_under.shape, y_train_under.shape, y_test_under.shape\n","\n","from sklearn.preprocessing import StandardScaler\n","\n","std_scaler_under = StandardScaler().fit(X_train_under)\n","\n","X_train_under_scaled = std_scaler_under.transform(X_train_under)\n","\n","X_test_under_scaled = std_scaler_under.transform(X_test_under)\n","\n","\n"]},{"cell_type":"code","source":["X_train_under_scaled.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KKVI1WuuN0bf","executionInfo":{"status":"ok","timestamp":1654824356849,"user_tz":-540,"elapsed":366,"user":{"displayName":"문서연","userId":"00100794801960082303"}},"outputId":"38583266-f25e-4de6-f713-a32201e4bcf5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(13140, 14)"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["\"\"\"# KNN\"\"\"\n","\n","from sklearn.neighbors import KNeighborsClassifier\n","\n","knn_clf = KNeighborsClassifier(n_neighbors=5).fit(X_train_under_scaled, y_train_under)\n","\n","knn_y_pred = knn_clf.predict(X_test_under_scaled)\n","\n","print(\"KNN Result\")\n","print(\"accuracy score : \", accuracy_score(y_test_under, knn_y_pred))\n","print(\"precision score\", precision_score(y_test_under, knn_y_pred))\n","print(\"recall score : \", recall_score(y_test_under, knn_y_pred))\n","print(\"f1 score : \", f1_score(y_test_under, knn_y_pred))\n","\n","\"\"\"# Logistic Regression\"\"\"\n","\n","from sklearn.linear_model import LogisticRegression\n","\n","log_clf = LogisticRegression(solver='liblinear', random_state=0).fit(X_train_under_scaled, y_train_under)\n","log_y_pred = log_clf.predict(X_test_under_scaled)\n","\n","print(\"Logistic Regression Result\")\n","print(\"accuracy score : \", accuracy_score(y_test_under, log_y_pred))\n","print(\"precision score\",  precision_score(y_test_under, log_y_pred))\n","print(\"recall score : \",  recall_score(y_test_under, log_y_pred))\n","print(\"f1 score : \",  f1_score(y_test_under, log_y_pred))\n","\n","\"\"\"# SVM\"\"\"\n","\n","from sklearn.svm import LinearSVC\n","from sklearn.pipeline import Pipeline\n","\n","svm_clf = Pipeline([\n","    (\"scaler\", StandardScaler()),\n","    (\"linear_svc\", LinearSVC(C=1))\n","])\n","    \n","svm_clf.fit(X_train_under, y_train_under)\n","\n","svm_y_pred = svm_clf.predict(X_test_under)\n","\n","print(\"SVM Result\")\n","print(\"accuracy score : \", accuracy_score(y_test_under, svm_y_pred))\n","print(\"precision score\",  precision_score(y_test_under, svm_y_pred))\n","print(\"recall score : \",  recall_score(y_test_under, svm_y_pred))\n","print(\"f1 score : \",  f1_score(y_test_under, svm_y_pred))\n","\n","\"\"\"# Decision Tree\"\"\"\n","\n","from sklearn.tree import DecisionTreeClassifier\n","\n","tree_clf = DecisionTreeClassifier(max_depth=4, max_leaf_nodes=10, random_state=0).fit(X_train_under_scaled, y_train_under)\n","\n","tree_y_pred = tree_clf.predict(X_test_under)\n","\n","\n","print(\"accuracy score : \", accuracy_score(y_test_under, tree_y_pred))\n","print(\"precision score\",  precision_score(y_test_under, tree_y_pred))\n","print(\"recall score : \",  recall_score(y_test_under, tree_y_pred))\n","print(\"f1 score : \", f1_score(y_test_under, tree_y_pred))\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n","\n","std_scaler = StandardScaler().fit(X_train)\n","\n","X_train_scaled = std_scaler.transform(X_train)\n","\n","X_test_scaled = std_scaler.transform(X_test)\n","\n","dtree_clf = DecisionTreeClassifier(max_depth=4, max_leaf_nodes=10, random_state=0).fit(X_train, y_train)\n","\n","dtree_y_pred = dtree_clf.predict(X_test)\n","\n","print(\"Decision Tree Result\")\n","print(\"accuracy score : \", accuracy_score(y_test, dtree_y_pred))\n","print(\"precision score\",  precision_score(y_test, dtree_y_pred))\n","print(\"recall score : \",  recall_score(y_test, dtree_y_pred))\n","print(\"f1 score : \", f1_score(y_test, dtree_y_pred))\n","\n","\"\"\"# Random Forest\"\"\"\n","\n","from sklearn.ensemble import RandomForestClassifier\n","\n","rand_clf = RandomForestClassifier(n_estimators=100, random_state=0).fit(X_train_under_scaled, y_train_under)\n","\n","rand_y_pred = rand_clf.predict(X_test_under)\n","\n","\n","print(\"accuracy score : \", accuracy_score(y_test_under, rand_y_pred))\n","print(\"precision score\",  precision_score(y_test_under, rand_y_pred))\n","print(\"recall score : \",  recall_score(y_test_under, rand_y_pred))\n","print(\"f1 score : \", f1_score(y_test_under, rand_y_pred))\n","\n","randf_clf = RandomForestClassifier(n_estimators=15, random_state=0).fit(X_train, y_train)\n","\n","randf_y_pred = randf_clf.predict(X_test)\n","\n","print(\"Random Forest Result\")\n","print(\"accuracy score : \", accuracy_score(y_test, randf_y_pred))\n","print(\"precision score\",  precision_score(y_test, randf_y_pred))\n","print(\"recall score : \",  recall_score(y_test, randf_y_pred))\n","print(\"f1 score : \", f1_score(y_test, randf_y_pred))"],"metadata":{"id":"u1rGjUDcM61S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"#ada boosting result\"\"\"\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import AdaBoostClassifier\n","from sklearn.metrics import precision_score, recall_score, f1_score\n","\n","dt = DecisionTreeClassifier(max_depth=1,   random_state=0)\n","#tree_clf = DecisionTreeClassifier(max_depth=4, max_leaf_nodes=10, random_state=0)\n","ada = AdaBoostClassifier(base_estimator= dt, n_estimators= 50, learning_rate = 0.5)\n","\n","# Fit ada to the training set\n","ada.fit(X_train, y_train)\n","\n","# Compute the probabilities of obtaining the positive class\n","y_pred = ada.predict(X_test)\n","\n","print(\"Ada Boosting Result\")\n","print(\"accuracy score : \", accuracy_score(y_test, y_pred))\n","print(\"precision score\",  precision_score(y_test, y_pred))\n","print(\"recall score : \",  recall_score(y_test, y_pred))\n","print(\"f1 score : \", f1_score(y_test, y_pred))\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"11iWmR4BUp6S","executionInfo":{"status":"ok","timestamp":1650934547068,"user_tz":-540,"elapsed":552889,"user":{"displayName":"문서연","userId":"00100794801960082303"}},"outputId":"22000359-cf0e-4733-847f-f881e303b313"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Ada Boosting Result\n","accuracy score :  0.9993438237707108\n","precision score 0.9653579676674365\n","recall score :  0.5094454600853139\n","f1 score :  0.6669325887514959\n"]}]},{"cell_type":"code","source":["\"\"\"#Gradient boosting result\"\"\"\n","from sklearn.ensemble import GradientBoostingClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","\n","# Instantiate gb\n","#dt = DecisionTreeClassifier(max_depth=1,   random_state=0)\n","#dt.fit(X_train, y_train)\n","\n","gb = GradientBoostingClassifier(max_depth = 3, n_estimators=100, random_state=0, learning_rate = 0.5)\n","\n","# Fit gb to the training set\n","gb.fit(X_train, y_train)\n","\n","# Predict test set labels\n","y_pred = gb.predict(X_test)\n","\n","print(\"Gradient Boosting Result\")\n","print(\"accuracy score : \", accuracy_score(y_test, y_pred))\n","print(\"precision score\",  precision_score(y_test, y_pred))\n","print(\"recall score : \",  recall_score(y_test, y_pred))\n","print(\"f1 score : \", f1_score(y_test, y_pred))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3GefSM7OUuzt","executionInfo":{"status":"ok","timestamp":1650936983473,"user_tz":-540,"elapsed":2436411,"user":{"displayName":"문서연","userId":"00100794801960082303"}},"outputId":"98ea140a-22c7-4668-8774-10465b8e04a1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Gradient Boosting Result\n","accuracy score :  0.9992542380340175\n","precision score 0.8333333333333334\n","recall score :  0.5271176112126752\n","f1 score :  0.6457633445315416\n"]}]},{"cell_type":"code","source":["\"\"\"#XGBoost result\"\"\"\n","import xgboost\n","from xgboost import XGBClassifier\n","\n","xgb = XGBClassifier(n_estimators = 100, learning_rate = 0.08, gamma = 0, subsample = 0.75, max_depth = 7, random_state = 0)\n","\n","# Train the model, this will take a few minutes to run\n","#bst = xgb.XGBRegressor(n_estimators = 100, learning_rate = 0.08, gamma = 0, subsample = 0.75, max_depth = 7, random_state = 0)\n","\n","xgb.fit(X_train, y_train)\n","# Get predictions on the test set and print the accuracy score\n","y_pred = xgb.predict(X_test)\n","\n","print(\"XGBoost Result\")\n","print(\"accuracy score : \", accuracy_score(y_test, y_pred))\n","print(\"precision score\",  precision_score(y_test, y_pred))\n","print(\"recall score : \",  recall_score(y_test, y_pred))\n","print(\"f1 score : \", f1_score(y_test, y_pred))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FAf2QFUUUxK6","executionInfo":{"status":"ok","timestamp":1650939153680,"user_tz":-540,"elapsed":2170210,"user":{"displayName":"문서연","userId":"00100794801960082303"}},"outputId":"321dfe79-d4eb-4f75-ea2a-eadc49679b15"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[01:36:26] WARNING: /workspace/src/learner.cc:686: Tree method is automatically selected to be 'approx' for faster speed. To use old behavior (exact greedy algorithm on single machine), set tree_method to 'exact'.\n","XGBoost Result\n","accuracy score :  0.9996880216011643\n","precision score 0.9712121212121212\n","recall score :  0.7812309567336989\n","f1 score :  0.8659236744343127\n"]}]},{"cell_type":"code","source":["import keras\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Flatten\n","from keras.layers.convolutional import Conv2D, MaxPooling2D\n","import numpy as np\n","\n","\n","model = keras.models.Sequential(\n","    keras.layers.SimpleRNN()\n",")"],"metadata":{"id":"jjwvVxM3L7GN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n","history = model.fit(epochs=10, validation_data=())\n","score = model.evaluate()\n","X_new = \n","y_pred = model.predic(X_new)"],"metadata":{"id":"yvt_XCEhPJU7"},"execution_count":null,"outputs":[]}]}